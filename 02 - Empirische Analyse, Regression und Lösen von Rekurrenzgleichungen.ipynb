{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirische Analyse\n",
    "\n",
    "Ist es nicht möglich, den Aufwand eines Algorithmus mit formalen Mitteln zu bestimmen, oder möchte man sich ein Algorihtmus in der Praxis verhalten könnte jenseits von asymptotischen Schranken, so kann man den Zeitwaufwand empirisch bestimmen. Dabei misst man, wie lange der Algorithmus zum Lösen eines Problems benötigt. Diese Messung wird mit unterschiedlichen Problemgrößen durchgeführt. Um ein repräsentatives Ergebnis zu bekommen, ist es empfehlenswert, Messungen mit unterschiedlichen Eingaben gleicher Größe durchzuführen, um zu verhindern, dass ein stark abweichender Wert einer Problemgröße das Ergebnis zu sehr verfälscht. Hat man diese Messungen durchgeführt, so kann man die gemittelten Werte in einem Streudiagramm (scatter plot) eintragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noJiZWSEcKGZmVggHipmZFeL/A2WSHDcaebj7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1728ea69d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import statistics\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def find_minimum(lst):\n",
    "    min_so_far = float('inf')\n",
    "    for n in lst:\n",
    "        min_so_far = min(min_so_far, n)\n",
    "    return min_so_far\n",
    "\n",
    "\n",
    "def get_random_lst(size, min_value=0, max_value=100000):\n",
    "    lst = []\n",
    "    for i in range(size):\n",
    "        lst.append(random.randint(min_value, max_value))\n",
    "    return lst\n",
    "\n",
    "\n",
    "def measure_time(algorithm):\n",
    "    def helper(*args):\n",
    "        start = time.clock()\n",
    "        algorithm(*args)\n",
    "        return time.clock() - start\n",
    "\n",
    "    return helper\n",
    "\n",
    "\n",
    "x = list(map(lambda n: 2 * n * 10 ** 4, list(range(1, 6))))\n",
    "y = list(map(lambda x: statistics.median(list(map(lambda _: measure_time(find_minimum)(get_random_lst(x)), range(5)))), x))\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('problem size n')\n",
    "plt.ylabel('elapsed time')\n",
    "plt.xlim(left=0)\n",
    "plt.ylim(bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Möchte man nun anstatt einem Streudiagramm eine Kurve, genauer eine Funktion, die den Anstieg des Zeitaufwands des Algorithmus angibt, haben, so bedarf es der Regression. Ziel der Regression ist es, eine Kurve so zu platzieren, dass sie einen möglichsten kleinen Abstand zu allen Punkten hat, die im Diagramm platziert wurden. Optisch entspricht es so etwa dem, als würde man durch die Punkte eine Linie bzw. Kurve zeichnen.\n",
    "\n",
    "### Einfache lineare Regression\n",
    "\n",
    "Bei der linearen Regression ist es Ziel, eine lineare Funktion als Annäherung für die Punkte anzugeben.\n",
    "\n",
    "Eine lineare Funktion ist wie folgt definiert:\n",
    "\n",
    "$$\n",
    "f(x) = a \\cdot x + b \\text{ mit $a, b \\in \\mathbb{R}$}\n",
    "$$\n",
    "\n",
    "Nun geht es darum $a$ und $b$ so zu wählen, dass der Verlauf der Gerade möglichst gut mit dem Verlauf der Punkte passt. Hierfür wird die Methode der kleinsten Qudrate anegewandt. Dabei wird für alle Punkte die Differenz zwischen dem Wert der Regressionsgerade un dem y-Wert des Punktes quadriert in Summe genommen. Nun muss $a$ und $b$ so angpasst werden, dass diese Summe minimal ist.\n",
    "\n",
    "<img src=\"http://cs.wellesley.edu/~cs199/lectures/line-fit-errors.png\" width=\"300\">\n",
    "\n",
    "- $x_i$ : $x$-Wert des $i$-ten Punkts\n",
    "- $y_i$ : $y$-Wert des $i$-ten Punkts\n",
    "\n",
    "$$\n",
    "e(a, b) = \\sum_{i=1}^n (a \\cdot x_i + b - y_i)^2\n",
    "$$\n",
    "\n",
    "Das Minimum lässt sich analytisch bestimmen, indem man die partiellen Ableitungen von $e(a, b)$ bildet und diese gleich 0 setzt.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "e(a, b) & = \\sum_{i=1}^n (a x_i + b)^2 - 2 \\cdot (a x_i + b) \\cdot y_i + y_i^2 \\\\\n",
    "& = \\sum_{i=1}^n a^2 x_i^2 + 2 a x_i b + b^2 - 2 a x_i y_i - 2 b y_i + y_i^2 \\\\\n",
    "\\frac{\\partial e(a, b)}{\\partial a} & = \\sum_{i=1}^n 2 x_i^2 a + 2 x_i b - 2 x_i y_i \\\\\n",
    "& = 2 \\sum_{i=1}^n x_i^2 a + x_i b - x_i y_i \\\\\n",
    "& = 2 \\left( \\sum_{i=1}^n x_i^2 a + \\sum_{i=1}^n x_i b - \\sum_{i=1}^n x_i y_i \\right) \\\\\n",
    "& = 2 \\left( a \\sum_{i=1}^n x_i^2 + b \\sum_{i=1}^n x_i - \\sum_{i=1}^n x_i y_i \\right) \\\\\n",
    "\\frac{\\partial e(a, b)}{\\partial b} & = \\sum_{i=1}^n 2 a x_i + 2 b - 2 y_i \\\\\n",
    "& = 2 \\sum_{i=1}^n a x_i + b - y_i \\\\\n",
    "& = 2 \\left( \\sum_{i=1}^n a x_i + \\sum_{i=1}^n b - \\sum_{i=1}^n y_i \\right) \\\\\n",
    "& = 2 \\left( a \\sum_{i=1}^n x_i + n b - \\sum_{i=1}^n y_i \\right) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Nun müssen die partiellen Ableitungen gleich 0 gesetzt werden.\n",
    "\n",
    "Im folgenden werden $\\overline{x}$ als das arithmetische Mittel von $x$ : $\\overline{x} = \\frac{\\sum_{i=1}^n x_i}{n}$ und $\\overline{y}$ als das arithmetische Mittel von $y$ : $\\overline{y} = \\frac{\\sum_{i=1}^n y_i}{n}$ bezeichnet.\n",
    "\n",
    "$$\n",
    "\\left\\{ \n",
    "\\begin{array}{c}\n",
    "\\begin{align*}\n",
    "2 \\left( a \\sum_{i=1}^n x_i^2 + b \\sum_{i=1}^n x_i - \\sum_{i=1}^n x_i y_i \\right) & = 0 \\\\\n",
    "2 \\left( a \\sum_{i=1}^n x_i + n b - \\sum_{i=1}^n y_i \\right) & = 0\n",
    "\\end{align*}\n",
    "\\end{array}\n",
    "\\right. \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left\\{ \n",
    "\\begin{array}{c}\n",
    "\\begin{align*}\n",
    "a \\sum_{i=1}^n x_i^2 + b \\sum_{i=1}^n x_i - \\sum_{i=1}^n x_i y_i & = 0 \\\\\n",
    "a \\sum_{i=1}^n x_i + n b - \\sum_{i=1}^n y_i & = 0\n",
    "\\end{align*}\n",
    "\\end{array}\n",
    "\\right. \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left\\{ \n",
    "\\begin{array}{c}\n",
    "\\begin{align*}\n",
    "a \\sum_{i=1}^n x_i^2 + b \\sum_{i=1}^n x_i & = \\sum_{i=1}^n x_i y_i \\\\\n",
    "a \\sum_{i=1}^n x_i + nb & = \\sum_{i=1}^n y_i\n",
    "\\end{align*}\n",
    "\\end{array}\n",
    "\\right. \n",
    "$$\n",
    "\n",
    "$$\n",
    "a \\sum_{i=1}^n x_i + nb = \\sum_{i=1}^n y_i \\\\\n",
    "\\iff b = \\frac{\\sum_{i=1}^n y_i - a \\sum_{i=1}^n x_i}{n} \\iff b = \\overline{y} - a \\overline{x} \\\\\n",
    "\\implies a \\sum_{i=1}^n x_i^2 + \\frac{\\sum_{i=1}^n y_i - a \\sum_{i=1}^n x_i}{n} \\sum_{i=1}^n x_i = \\sum_{i=1}^n x_i y_i \\\\\n",
    "\\iff a \\sum_{i=1}^n x_i^2 + \\frac{\\sum_{i=1}^n x_i \\sum_{i=1}^n y_i}{n} - a \\frac{\\left( \\sum_{i=1}^n x_i \\right)^2}{n} = \\sum_{i=1}^n x_i y_i \\\\\n",
    "\\iff a \\sum_{i=1}^n x_i^2 - a \\frac{\\left( \\sum_{i=1}^n x_i \\right)^2}{n} = \\sum_{i=1}^n x_i y_i - \\frac{\\sum_{i=1}^n x_i \\sum_{i=1}^n y_i}{n} \\\\\n",
    "\\iff a \\left( \\sum_{i=1}^n x_i^2 - \\frac{\\left( \\sum_{i=1}^n x_i \\right)^2}{n} \\right) = \\sum_{i=1}^n x_i y_i - \\frac{\\sum_{i=1}^n x_i \\sum_{i=1}^n y_i}{n} \\\\\n",
    "\\iff a = \\frac{\\sum_{i=1}^n x_i y_i - \\frac{\\sum_{i=1}^n x_i \\sum_{i=1}^n y_i}{n}}{\\sum_{i=1}^n x_i^2 - \\frac{\\left( \\sum_{i=1}^n x_i \\right)^2}{n}} \\\\\n",
    "\\iff a = \\frac{\\sum_{i=1}^n x_i y_i - \\frac{n \\cdot \\overline{x} \\cdot n \\cdot \\overline{y}}{n}}{\\sum_{i=1}^n x_i^2 - \\frac{n \\cdot \\overline{x} \\cdot n \\cdot \\overline{x}}{n}} \\\\\n",
    "\\iff a = \\frac{\\sum_{i=1}^n x_i y_i - n \\cdot \\overline{x} \\cdot \\overline{y}}{\\sum_{i=1}^n x_i^2 - n \\cdot \\overline{x}^2}\n",
    "$$\n",
    "\n",
    "Nun hat man mit \n",
    "\n",
    "$$\n",
    "a = \\frac{\\sum_{i=1}^n x_i y_i - n \\cdot \\overline{x} \\cdot \\overline{y}}{\\sum_{i=1}^n x_i^2 - n \\cdot \\overline{x}^2}\n",
    "$$ \n",
    "\n",
    "und \n",
    "\n",
    "$$\n",
    "b = \\overline{y} - a \\overline{x}\n",
    "$$ \n",
    "\n",
    "Formeln, mit denen man die beiden Variablen der Linearfunktion bestimmen kann.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/1200px-Linear_regression.svg.png\" width=\"350\">\n",
    "\n",
    "### Exponentielle Regression\n",
    "\n",
    "Bei der exponentiellen Regression möchte man eine Exponentialfunktion finden, die sich möglichst gut an die gegebenen Punkte anschmiegt. Dieses Problem lässt sich auf das Problem eine lineare Funktion zu finden reduzieren, indem man die y-Achse logarithmisch anlegt. Nun verläuft die Kurve geradlinig, wenn sie eine Exponentialfunktion darstellt. Deshalb lässt sich das bereits bekannte Verfahren der linearen Regression anwenden.\n",
    "\n",
    "Wählt man als Basis 2, so möchte man eine Funktion der Form $f(x) = a \\cdot 2^{bx}$ finden. Logarithmiert man den Funktionwert, so erhält man: \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\log_2 \\left(f(x) \\right) & = \\log_2 \\left(a \\cdot 2^{bx} \\right) \\\\\n",
    "& = \\log_2 a + \\log_2 2^{bx} \\\\\n",
    "& = \\log_2 a + bx\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Es handelt sich um eine lineare Funktion und $b$ und $\\log_2 a$ lassen sich wie oben beschrieben bestimmen.\n",
    "\n",
    "\n",
    "### Polynomielle Regression\n",
    "\n",
    "Bei der polynomiellen Regression möchte man eine Funktion der Form $f(x) = a \\cdot x^k$ finden, die die Punkte möglichst gut annähert. Nun müss die Kombination aus $a$ und $k$ gefunden werden, für die der Fehler minimal ist.\n",
    "\n",
    "Hierfür wird wieder das Logarithmieren der Achsen benutzt. Jedoch wird hier nicht nur die y-Achse, sondern auch die x-Achse logarithmiert. Die Basis des Logarithmus ist egal, es muss sich allerdings bei der x- und y-Achse um die gleiche Basis handeln.\n",
    "\n",
    "__Beispiele:__\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/LogLog_exponentials.svg/512px-LogLog_exponentials.svg.png\" width=\"300\">\n",
    "\n",
    "Durch Logarithmieren der y-Achse erhält man:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(x) &= a \\cdot x^k \\\\\n",
    "\\implies \\log(f(x)) &= \\log(a \\cdot x^k) \\\\\n",
    "\\implies \\log(f(x)) &= k \\log(x) + \\log(a)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Setzt man nun die x-Achse (mit $x'$ gekennzeichnet) $x' = \\log(x)$, so erhält man eine Gerade. $\\log(a)$ gibt den y-Achsenschnittpunkt und $k$ den Anstieg der Geraden an.\n",
    "\n",
    "Nun kann man wie bei der linearen Regression vorgehen und $k$ und $\\log(a)$ bestimmen.\n",
    "\n",
    "### Korrelationskoeffizient\n",
    "\n",
    "Der Pearson-Korrelationskoeffizient $r$ ist ein Maß für die Beziehung zwischen zwei Variablen. Im Zusammenhang der linearen Regression kann er genutzt werden, um die Qualität der Regressiongerade zu bestimmen.\n",
    "\n",
    "$$\n",
    "r = \\frac{cov(X, Y)}{\\sigma_X \\sigma_Y}\n",
    "$$\n",
    "\n",
    "$cov(X, Y)$ ist die Kovarianz von $X$ und $Y$ und wird folgendermaßen bestimmt:\n",
    "$$\n",
    "cov(X, Y) = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\overline{x}) (y_i - \\overline{y})\n",
    "$$\n",
    "\n",
    "Eingesetzt ergibt sich für $r$ folgende Formel:\n",
    "\n",
    "$$\n",
    "r = \\frac{\\frac{1}{n} \\sum_{i=1}^n (x_i - \\overline{x}) (y_i - \\overline{y})}{\\sqrt{\\frac{1}{n} \\sum_{i=1}^n (x_i - \\overline{x})^2} \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - \\overline{y})^2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "r = \\frac{\\sum_{i=1}^n (x_i - \\overline{x}) (y_i - \\overline{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\overline{x})^2} \\sqrt{\\sum_{i=1}^n (y_i - \\overline{y})^2}}\n",
    "$$\n",
    "\n",
    "Laut der Cauchy-Schwartzen Ungleichung gilt:\n",
    "\n",
    "$$\n",
    "\\left| \\sum_{i=1}^n (x_i - \\overline{x}) (y_i - \\overline{y}) \\right|^2 \\leqslant \\sum_{i=1}^n (x_i - \\overline{x})^2 \\sum_{i=1}^n (y_i - \\overline{y})^2 \\implies \\sum_{i=1}^n (x_i - \\overline{x}) (y_i - \\overline{y}) \\leqslant \\sqrt{\\sum_{i=1}^n (x_i - \\overline{x})^2} \\sqrt{\\sum_{i=1}^n (y_i - \\overline{y})^2} \\implies \\left| r \\right| \\leqslant 1 \\implies -1 \\leqslant r \\leqslant 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lösen von Rekurrenzgleichungen\n",
    "\n",
    "Viele Algorithmen basieren auf Rekursion. Dann folgt der Zeitaufwand der rekursiven Berechnungsvorschrift des gesuchten Resultats. Für die Effizienzanalyse solcher Algorithmen benötigen wir ein Verfahren, mit dem rekursive Gleichungen (Rekurrenzgleichungen) gelöst werden können.\n",
    "\n",
    "Ein typisches Beispiel ist die Fibonacci-Folge: $0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55,\\ldots$.\n",
    "\n",
    "Die Bildungsvorschrift der $n$-ten Fibonacci-Zahl lässt sich sehr leicht angegeben, wenn dies rekursiv geschieht:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "fib(0) & = 0 \\\\\n",
    "fib(1) & = 1 \\\\\n",
    "fib(n) & = fib(n - 1) + fib(n - 2) \\mid n \\geqslant 2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Die $n$-te Fibonacci-Zahl ist gleich der Summe der zwei vorhergehenden Zahlen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181]\n"
     ]
    }
   ],
   "source": [
    "def fib(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    return fib(n-1) + fib(n-2)\n",
    "\n",
    "print(list(map(fib, list(range(0, 20)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Zeitaufwand lässt sich ebenfalls durch eine rekursive Gleichung ausdrücken:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "T(0) & = 0 \\\\\n",
    "T(1) & = 1 \\\\\n",
    "T(n) & = T(n - 1) + T(n - 2), n\\geqslant 2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Für $T$ benötigen wir einen Ausdruck in $n$ allerdings ohne $T(i)$ auf der rechten Seite. Gibt es ein Verfahren, um aus der (leicht erkennbaren) rekursiven Definition eine explizite zu gewinnen.\n",
    "\n",
    "In der Tat gibt es sogar mehrere solcher Verfahren, die das Gewünschte mehr oder weniger erfolgreich leisten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raten und Einsetzen\n",
    "\n",
    "Eine solche Lösungsmethode ist das __Intelligent guesswork__ - das geschickte Raten. Hierfür stellt man eine Wertetabelle für $T(n)$ auf und versucht daraus eine explizite Bildungsvorschrift zu erkennen.\n",
    "\n",
    "__Beispiel__\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "T(1) & = 1 \\\\\n",
    "T(n) & = 3 \\cdot T \\left(\\frac{n}{2} \\right) + n\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$n$ sei hierbei eine Zweierpotenz, d.h. $n = 2^k$ mit $k \\in \\mathbb{N}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Implementierung mit Python verwenden wir die pandas-Bibliothek zur Verwaltung und Analyse von Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     T(n)\n",
      "2       5\n",
      "4      19\n",
      "8      65\n",
      "16    211\n",
      "32    665\n",
      "64   2059\n",
      "128  6305\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def T(n):\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    return 3 * T(n/2) + n\n",
    "\n",
    "\n",
    "args = list(map(lambda n: 2**n, list(range(1, 8))))\n",
    "\n",
    "print(pd.DataFrame({'T(n)': pd.Series(map(T, args), index=args, dtype=int)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gibt man zusätzlich zu den Funktionswerten die Summendarstellungen an, ergibt sich folgende Wertetabelle:\n",
    "\n",
    "|$n$|$T(n)$|\n",
    "|---:|---:|\n",
    "|$1$|$1$|\n",
    "|$2$|$5=3 \\cdot 1 + 2$|\n",
    "|$4$|$19=3^2 \\cdot 1 + 3 \\cdot 2 + 2^2$|\n",
    "|$8$|$65=3^3 \\cdot 1 + 3^2 \\cdot 2 + 3 \\cdot 2^2 + 2^3$|\n",
    "|$16$|$211=3^4 \\cdot 1 + 3^3 \\cdot 2 + 3^2 \\cdot 2^2 + 3 \\cdot 2^3 + 2^4$|\n",
    "|$32$|$665=3^5 \\cdot 1 + 3^4 \\cdot 2 + 3^3 \\cdot 2^2 + 3^2 \\cdot 2^3 + 3 \\cdot 2^4 + 2^5$|\n",
    "\n",
    "Mit Hilfe dieser Summendarstellung lässt sich ein gewisses Muster erkennen, dadurch kann die Lösung \"erraten\" werden.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(2^k) & = 3^k \\cdot 2^0 + 3^{k-1} \\cdot 2^1 + ... + 3^1 \\cdot 2^{k-1} + 3^0 \\cdot 2^k \\\\\n",
    " & = \\sum_{i=0}^{k}(3^{k-i} \\cdot 2^i) \\\\\n",
    " & = 3^k \\sum_{i=0}^k \\left(\\frac{2}{3} \\right)^i \\\\\n",
    " & = 3^k \\frac{1- \\left(\\frac{2}{3}^{k+1} \\right)}{1-\\frac{2}{3}} \\\\\n",
    "T(2^k) & = 3^{k+1} - 2^{k+1}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Um eine Funktion $n \\mapsto T(n)$ zu erhalten, muss $k$ durch $\\log_2 n$ ersetzt werden.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(n) & = 3^{\\log_2 n + 1} - 2^{\\log_2 n + 1} \\\\\n",
    " & = 3^{\\log_2 n} \\cdot 3^1 - 2^{\\log_2 n} \\cdot 2^1 \\\\\n",
    " & = 3 \\cdot 3^{\\log_2 n} - 2 \\cdot 2^{\\log_2 n} \\\\\n",
    "T(n) & = 3 \\cdot n^{\\log_2 3} - 2 \\cdot n\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Um die asymptotische Aufwandsordnung anzugeben, können der Summand $-2n$ und der Faktor $3$ vernachlässigt werden. Dies ergibt $\\mathcal{O}(n^{\\log_2 3})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Iterationsmethode\n",
    "\n",
    "Bei der __Iterationsmethode__ wird eine rekursive Vorschrift solange angewandt, bis man zu einem rekursionsfreien Ausdruck gelangt. Dies geschieht durch wiederholtes Einsetzen der rekursiven Funktionsaufrufe. Diese Expansion durch Selbstanwendung wird __Telescoping__ genannt.\n",
    "\n",
    "Hat man eine rekursive Funktion $n\\mapsto T(n)$ und setzt man für $n$ einen konkreten Wert ein, so kann problemlos Telescoping angewandt werden, da in endlich vielen Schritten die Elementarfälle erreicht werden und ein rekursionsfreier Ausdruck entsteht. Möchte man aber eine rekursive Funktion $n\\mapsto T(n)$ für ein allgemeines $n$ mit Hilfe der Iterationsmethode lösen, so ist ein mathematischer Zwischenschritt nötig.\n",
    "\n",
    "__Beispiel__\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(1) & = 1 \\\\\n",
    "T(n) & = 2 \\cdot T \\left(\\frac{n}{4} \\right) + n\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Die Gleichung wird nun schrittweise expandiert:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(n) & = 2 \\cdot T \\left(\\frac{n}{4} \\right) + n \\\\\n",
    " & = 2 \\cdot \\left(2 \\cdot T \\left(\\frac{n}{16} \\right) + \\frac{n}{4} \\right) + n \\\\\n",
    " & = 4 \\cdot T \\left(\\frac{n}{16} \\right) + \\frac{3}{2}n \\\\\n",
    " & = 4 \\cdot \\left(2 \\cdot T \\left(\\frac{n}{64} \\right) + \\frac{n}{16} \\right) + \\frac{3}{2}n \\\\\n",
    " & = 8 \\cdot T \\left(\\frac{n}{64} \\right) + \\frac{7}{4}n \\\\\n",
    " & = 8 \\cdot \\left(2 \\cdot T \\left(\\frac{n}{256} \\right) + \\frac{n}{64} \\right) + \\frac{7}{4}n \\\\\n",
    " & = 16 \\cdot T \\left(\\frac{n}{256} \\right) + \\frac{15}{8}n \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Es wird ein gewisses Muster für den gesuchten, $T(n)$ definierenden Ausdruck ersichtlich, welches sich mit einer Variable $i$ mit $i\\geqslant 1$ ausdrücken lässt.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(n) & = 2^i \\cdot T \\left(\\frac{n}{4^i} \\right) + \\frac{2^i - 1}{2^{i-1}} \\cdot n \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Nun muss $i$ so gewählt werden, dass aus $T\\left(\\frac{n}{4^i}\\right)$ ein rekursionsfreier Ausdruck ensteht, d.h. der Elementarfall erreicht ist. Dies geschieht mit $i = \\log_4 n$ bei $T(1)$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T\\left(\\frac{n}{4^i}\\right) & = T(1) \\\\\n",
    "\\frac{n}{4^i} & = 1 \\\\\n",
    "n & = 4^i \\\\\n",
    "i & = \\log_4 n\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Wir setzen $\\log_4 n$ für $i$ in dem oben für $T(n)$ angegebenen \"Musterausdruck\" ein:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(n) & = 2^{\\log_4 n} \\cdot T \\left(\\frac{n}{4^{\\log_4 n}} \\right) + \\frac{2^{\\log_4 n} - 1}{2^{\\log_4 n - 1}} \\cdot n \\\\\n",
    " & = n^{\\log_4 2} \\cdot T(1) + \\frac{n^{\\log_4 2} - 1}{\\frac{2^{\\log_4 n}}{2}} \\cdot n \\\\\n",
    " & = n^{\\log_4 2} \\cdot T(1) + \\frac{n^{\\log_4 2} - 1}{\\frac{n^{\\log_4 2}}{2}} \\cdot n \\\\\n",
    " & = n^{\\frac{1}{2}} \\cdot T(1) + \\frac{n^{\\frac{1}{2}} - 1}{\\frac{n^{\\frac{1}{2}}}{2}} \\cdot n \\\\\n",
    " & = n^{\\frac{1}{2}} + \\frac{2n^{\\frac{1}{2}} - 2}{n^{\\frac{1}{2}}} \\cdot n \\\\\n",
    " & = n^{\\frac{1}{2}} + \\frac{2n^{\\frac{3}{2}} - 2n}{n^{\\frac{1}{2}}} \\\\\n",
    " & = n^{\\frac{1}{2}} + \\frac{2n^{\\frac{3}{2}} - 2n}{n^{\\frac{1}{2}}} \\\\\n",
    " & = n^{\\frac{1}{2}} + 2n - 2n^\\frac{1}{2} \\\\\n",
    "T(n) & = 2n - n^\\frac{1}{2}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Interessiert man sich nur für die asymptotische Aufwandsordnung, so liegt mit $T(n) \\in \\mathcal{O}(n)$ ein linearer Zusammenhang vor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meistermethode (Master method)\n",
    "\n",
    "Die __Meistermethode__ bietet eine Möglichkeit, die asymptotische Aufwandsordnung für [Divide and Conquer-Algorithmen](/notebooks/Documents/algorithmen-und-komplexitaet/08%20-%20Divide%20and%20Conquer.ipynb) anzugeben. Der Zeitaufwand von Divide and Conquer-Algorithmen lässt sich in der Form $T(n) = a \\cdot T \\left(\\frac{n}{b} \\right) + f(n)$ angeben. \n",
    "\n",
    "__Beispiel__\n",
    "\n",
    "Für $T(n) = 2 \\cdot T \\left(\\frac{n}{4} \\right) + n$ lassen sich $a$, $b$ und $f(n)$ folgendermaßen angeben:\n",
    "$$\n",
    "\\begin{align}\n",
    "a & = 2 \\\\\n",
    "b & = 4 \\\\\n",
    "f(n) & = n\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "<div class=\"general-text\">\n",
    "Nun muss man versuchen, den Ausdruck in einen der folgenden drei Fälle einzuordnen. Wenn dies gelingt, ergibt sich die Lösung unmittelbar aus der Variablenbindung. Wenn nicht, ist die Mastermethode zur Lösung der vorliegenden Rekurrenzgleichung nicht anwendbar.\n",
    "</div>\n",
    "\n",
    "__Definition 2.1 (Master Theorem)__\n",
    "\n",
    "### Fall 1\n",
    "\n",
    "Wenn $f(n) \\in \\mathcal{O} \\left(n^{\\log_b a - \\epsilon} \\right)$ mit $\\epsilon > 0$, dann $T(n) \\in \\Theta \\left(n^{\\log_b a} \\right)$.\n",
    "\n",
    "Der größte Aufwand besteht hier im Teilen in Subprobleme, die Rekursion ist somit wurzellastig (root-heavy).\n",
    "\n",
    "### Fall 2\n",
    "\n",
    "Wenn $f(n) \\in \\Theta \\left(n^{\\log_b a} \\right)$, dann $T(n) \\in \\Theta \\left(n^{\\log_b a}\\log n \\right)$.\n",
    "\n",
    "Der Aufwand zum Rekombinieren der gelösten Subprobleme ist gleichwertig mit dem des Teilens.\n",
    "\n",
    "### Fall 3\n",
    "\n",
    "Wenn $f(n) \\in \\Omega \\left(n^{\\log_b a + \\epsilon} \\right)$ mit $\\epsilon > 0$, dann $T(n) \\in \\Theta(f(n))$.\n",
    "\n",
    "In diesem Fall liegt der größte Aufwand im Rekombinieren, die Rekursion ist also blattlastig (leaf-heavy).\n",
    "\n",
    "__Beispiel__\n",
    "\n",
    "Für das oben angegebene Beispiel gilt Fall 3 des Master Theorems:\n",
    "\n",
    "$f(n) = n \\in \\Omega \\left(n^{\\log_b a + \\epsilon} \\right) \\implies f(n) \\in \\Omega \\left(n^{\\log_4 2 + \\epsilon} \\right) \\implies f(n) \\in \\Omega \\left(n^{\\frac{1}{2} + \\epsilon} \\right)$ mit $\\epsilon=\\frac{1}{2} > 0$.\n",
    "\n",
    "Folglich gilt für die Aufwandsordnung $T(n)\\in\\Theta(f(n)) \\implies T(n)\\in\\Theta(n)$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
