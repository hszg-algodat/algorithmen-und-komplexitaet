{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amortisierte Analyse\n",
    "\n",
    "\n",
    "Nicht immer ist die Angabe der worst-case Komplexität hilfreich. Was ist nämlich, wenn der worst-case nur sehr selten eintritt, aber in den meisten Fällen eine wesentlich bessere Laufzeit erzielt wird? Dies ist z.B. beim Hinzufügen von Elementen in ein dynamisches Array der Fall. In den meisten Fällen geht dies problemlos mit einem Aufwand von $\\mathcal{O}(1)$, doch ist das Array nicht lang genug, so müssen alle Werte in eine neues Array kopiert werden, was zu einem Aufwand von $\\mathcal{O}(n)$ führt. Dadurch liegt die worst-case Komplexität bei $\\mathcal{O}(n)$, was zunächst ziemlich schlecht zu sein scheint, da andere Datenstrukturen dies (selbst im worst-case) in $\\mathcal{O}(1)$ können. Um hier eine genaue Aussage treffen zu können, bedarf es der amortisierten Analyse.\n",
    "\n",
    "\n",
    "Die amoritsierte Analyse (amortized analysis) berechnet die mittleren Kosten über eine Folge von Operationen, in der viele dieser Operationen billig sind und nur wenige teuer in Bezug auf deren Beitrag zur Gesamtzeit.\n",
    "\n",
    "## Aggregat-Analyse\n",
    "\n",
    "__Satz 4.1__ Bei der Aggregat-Analyse gilt:\n",
    "\n",
    "$$T(n)_{amort} = \\frac{\\text{Summe der Kosten aller Operationen}}{\\text{Anzahl der Operationen}}$$\n",
    "\n",
    "Die Kosten der Operationen $1, 2, ..., n$ wird durch die Anzahl $n$ der Operationen geteilt.\n",
    "\n",
    "\n",
    "### Dynamisches Array\n",
    "\n",
    "Bei einem dynamischen Array wird zunächst ein Array der Größe 1 initialisiert. Sobald der Platz nicht mehr ausreicht und man das $n+1$. Element einfügen möchte, so wird ein neues Array mit doppelter Länge erstellt und die bisherigen Werte reinkopiert. Sollte dieses nicht mehr ausreichen, so wird auch dieses wieder verdoppelt.\n",
    "\n",
    "Die amortisierten Kosten betragen:\n",
    "\n",
    "__*Beweis.*__\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(n)_{gesamt} & = n + 1 + \\dotsc + 1 + \\frac{n}{2} + 1 + \\dotsc + 1 + \\frac{n}{4} + 1 + \\dotsc + 1 + \\frac{n}{8} + \\dotsc + 1 \\\\\n",
    " & = \\sum_{i=0}^{\\infty} n \\cdot \\left(\\frac{1}{2} \\right)^i  + (n - \\log_2 n) \\cdot 1 \\\\\n",
    " & = n \\cdot \\sum_{i=0}^{\\infty} \\left(\\frac{1}{2}\\right)^i + (n - \\log_2 n) \\cdot 1 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Da es sich bei der Summe um eine geometrische Reihe handelt, kann sie aufgelöst werden.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(n)_{gesamt} & = n \\cdot \\frac{1}{1-\\frac{1}{2}} + (n - \\log_2 n) \\cdot 1 \\\\\n",
    " & = 2n + (n - \\log_2 n) \\cdot 1 \\\\\n",
    " & = 2n + \\mathcal{O}(n) \\\\\n",
    " & \\in \\mathcal{O}(n)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(n)_{amort} & = \\frac{\\mathcal{O}(n)}{n} \\\\\n",
    " & \\in \\mathcal{O}(1)\n",
    "\\end{align*}\n",
    "$$\n",
    "<div style=\"text-align: right; font-size: 24px;\">&#9633;</div>\n",
    "\n",
    "Damit ergeben sich für die Insert-Opertion bei einem dynamischen Array amortisierte Kosten von $\\mathcal{O}(1)$.\n",
    "\n",
    "### Binärzähler\n",
    "\n",
    "Situation: $n$ Inkrementierungen eines $k$-Bit-Binärzählers mit Anfangswert 0\n",
    "\n",
    "Array: $A[0 \\dotsc k-1], A[i] \\in \\{0,1\\},$\n",
    "\n",
    "$$x = \\sum_{i=0}^{k-1} A[i] \\cdot 2^i$$\n",
    "\n",
    "Worst case: Alle $k$ Bits werden invertiert, da sie von 1 auf 0 wechseln. Dies ist beim Übergang von $2^i - 1$ zu $2^i$ der Fall. Folglich beträgt der Aufwand je Inkrementierungsschritt im schlechtesten Fall $\\mathcal{O}(k) = \\mathcal{O}(\\log n)$. Dies ist zwar korrekt, aber zu grob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A[6]  A[5] A[4] A[3] A[2] A[1] A[0]  Total costs\n",
      "0      0     0    0    0    0    0    0            0\n",
      "1      0     0    0    0    0    0    1            1\n",
      "2      0     0    0    0    0    1    1            3\n",
      "3      0     0    0    0    0    0    1            4\n",
      "4      0     0    0    0    1    1    1            7\n",
      "5      0     0    0    0    0    0    1            8\n",
      "6      0     0    0    0    0    1    1           10\n",
      "7      0     0    0    0    0    0    1           11\n",
      "8      0     0    0    1    1    1    1           15\n",
      "9      0     0    0    0    0    0    1           16\n",
      "10     0     0    0    0    0    1    1           18\n",
      "11     0     0    0    0    0    0    1           19\n",
      "12     0     0    0    0    1    1    1           22\n",
      "13     0     0    0    0    0    0    1           23\n",
      "14     0     0    0    0    0    1    1           25\n",
      "15     0     0    0    0    0    0    1           26\n",
      "16     0     0    1    1    1    1    1           31\n",
      "17     0     0    0    0    0    0    1           32\n",
      "18     0     0    0    0    0    1    1           34\n",
      "19     0     0    0    0    0    0    1           35\n",
      "20     0     0    0    0    1    1    1           38\n",
      "21     0     0    0    0    0    0    1           39\n",
      "22     0     0    0    0    0    1    1           41\n",
      "23     0     0    0    0    0    0    1           42\n",
      "24     0     0    0    1    1    1    1           46\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def increment_cost(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    return n ^ (n-1)\n",
    "\n",
    "\n",
    "def total_costs(bin_strings):\n",
    "    if len(bin_strings) == 0:\n",
    "        return []\n",
    "    total_costs_lst = total_costs(bin_strings[:-1])\n",
    "    if len(total_costs_lst) == 0:\n",
    "        total_cost = 0\n",
    "    else:\n",
    "        total_cost = total_costs_lst[len(total_costs_lst)-1]\n",
    "    for digit in bin_strings[len(bin_strings)-1]:\n",
    "        if digit == \"1\":\n",
    "            total_cost += 1\n",
    "    return total_costs_lst + [total_cost]\n",
    "            \n",
    "    \n",
    "A_cost = []\n",
    "max_n = 25\n",
    "inc_costs = []\n",
    "\n",
    "for i in range(0, max_n):\n",
    "    inc_costs.append(\"{0:b}\".format(increment_cost(i)))\n",
    "\n",
    "for i in range(0, 7):\n",
    "    A_cost.append(list())\n",
    "    for j in range(0, max_n):\n",
    "        A_cost[i].append(0)\n",
    "\n",
    "for n in range(0, max_n):\n",
    "    inc_cost = \"{0:b}\".format(increment_cost(n))\n",
    "    for i in reversed(range(0, len(inc_cost))):\n",
    "        A_cost[i][n] = inc_cost[i]\n",
    "        \n",
    "        \n",
    "table = pd.DataFrame({'A[6]': pd.Series(A_cost[6]),\n",
    "                     'A[5]': pd.Series(A_cost[5]),\n",
    "                     'A[4]': pd.Series(A_cost[4]),\n",
    "                     'A[3]': pd.Series(A_cost[3]),\n",
    "                     'A[2]': pd.Series(A_cost[2]),\n",
    "                     'A[1]': pd.Series(A_cost[1]),\n",
    "                     'A[0]': pd.Series(A_cost[0]),\n",
    "                    'Total costs': pd.Series(total_costs(inc_costs))}, \n",
    "                   columns=['A[6]', 'A[5]', 'A[4]', 'A[3]', 'A[2]', 'A[1]', 'A[0]', 'Total costs'])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Die Tabelle zeigt, wann ein Bit invertiert werden muss. In diesem Fall steht eine 1 an dem entsprechenden Index. Man kann beobachten, dass $A[0]$ $n$-mal invertiert wird, $A[1]$ wird in jedem zweiten Schritt invertiert, also $\\frac{n}{2}$-mal. Veralgemeinert kann man sagen, dass $A[i]$ $\\frac{n}{2^i}$-mal invertiert werden muss. Für die Gesamtkosten ergibt sich also:\n",
    "\n",
    "__*Beweis.*__\n",
    "$$T(n)_{\\text{gesamt}} = \\sum_{i=0}^{k-1} \\frac{n}{2^i} = n \\cdot \\sum_{i=0}^{k-1} \\frac{1}{2^i} < n \\cdot \\sum_{i=0}^{\\infty} \\frac{1}{2^i} = 2n \\in \\mathcal{O}(n)$$\n",
    "\n",
    "$$T(n) = \\frac{\\mathcal{O}(n)}{n} \\in \\mathcal{O}(1)$$\n",
    "<div style=\"text-align: right; font-size: 24px;\">&#9633;</div>\n",
    "\n",
    "Es ergibt sich also ein amortiesierter Aufwand von $\\mathcal{O}(1)$ für die Inkrement-Operation.\n",
    "\n",
    "Die Aggregat Methode ist die einfachste Methode zur amortisierten Analyse, jedoch lassen sich komplexere Algorithmen mit ihr nicht lösen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accounting Methode\n",
    "\n",
    "Bei der Accounting Methode gibt es ein Bankkonto, auf welches man Guthaben laden kann. Dieses Guthaben kann man sich als Münzen vorstellen, die eingezahlt werden, wenn eine Operation billig ist (also sehr geringer Zeitaufwand). Bei Operationen mit hohen Kosten (großer Zeitaufwand) besteht die Möglichkeit, vorhandenes Guthaben vom Konto zu nehmen und damit die Operation zu \"bezahlen\". Der Betrag auf dem Konto darf dabei nicht negativ werden, man möchte nämlich zeigen, dass die tatsächlichen Kosten $\\leqslant$ amortisierte Kosten sind.\n",
    "\n",
    "### Dynamisches Array\n",
    "\n",
    "Hier wird folgendermaßen vorgegangen:\n",
    "\n",
    "- wenn eine Insertion-Operation keine Verdopplung verursacht, zahlt man eine Münze mit dem Wert $\\mathcal{O}(1)$ in das Konto ein.\n",
    "- wenn eine Insertion-Operation eine Verdopplung verursacht, so wurden seit der letzten Verdopplung $\\frac{n}{2}$ Elemente eingefügt. $\\frac{n}{2}$ Münzen können nun verwendet werden um die $\\mathcal{O}(n)$ Operation zu bezahlen.\n",
    "\n",
    "<img src=\"img/table-doubling-accounting-method.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "- amortisierte Kosten für eine Verdopplung: $\\mathcal{O}(n) - c \\cdot \\frac{n}{2} = 0$ für ein $c$, das groß genug ist. (In dem Fall $c=2$)\n",
    "- da $c$ eine Konstante ist, gilt dass die amortisierten Kosten für eine Insert-Operation $1 + c \\in \\mathcal{O}(1)$ sind.\n",
    "\n",
    "\n",
    "## Potenzial Methode\n",
    "\n",
    "Bei der Potenzial Methode, bzw. beim Beweis mit Potenzialfunktion, wird eine Funktion definiert, die von einer Datenstruktur in einem bestimmten Zustand auf eine reelle nicht-negative Zahl abbildet. Diesen Wert bezeichnet man als Potenzial. Dieses Konzept ähnelt der Accounting Methode.\n",
    "\n",
    "__Definition 4.2__ Es wird eine Datenstruktur zum Zeitpunkt $i$ als $D_i$ betrachtet. Zu definieren ist also eine Potenzialfunktion $\\Phi : D_i \\rightarrow \\mathbb{R^+_0}$. Die tatsächlichen Kosten einer Operation werden $c_i$ bezeichnet. Für die amortisierten Kosten $\\hat{c}_i$ ergibt sich folgende Gleichung:\n",
    "\n",
    "$$\n",
    "\\hat{c}_i = c_i + \\Delta \\Phi(D_i) = c_i + \\Phi(D_i) - \\Phi(D_{i-1})\n",
    "$$\n",
    "\n",
    "Die amortisierten Kosten einer Operation sind die Summe aus den tatsächlichen Kosten dieser Operation und der Veränderung der Potenzialfunktion, die durch diese Operation verursacht wird. Die Veränderung der Potenzialfunktion ist gleich der Differenz aus $\\Phi$ zum Zeitpunkt $i$ und $\\Phi$ zum Zeitpunkt $i-1$.\n",
    "\n",
    "Intuitiv kann man sagen, dass die Potenzialfunktion angeben soll, wie labil der aktuelle Zustand der Datenstruktur gegenüber teure Operationen ist, d.h. wie nah die nächste teure Operation ist.\n",
    "\n",
    "Aus der Gleichung für die amortisierten Kosten $\\hat{c}_i$ lässt sich eine Gleichung für die amortisierten Kosten aller Operationen von 1 bis $n$ herleiten:\n",
    "\n",
    "__Lemma 4.3__\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\sum_{i=1}^n \\hat{c}_i &= \\sum_{i=1}^n c_i + \\sum_{i=1}^n (\\Phi(D_i) - \\Phi(D_{i-1})) \\\\\n",
    " &= \\sum_{i=1}^n c_i + (\\Phi(D_1) - \\Phi(D_0) + \\Phi(D_2) - \\Phi(D_1) + \\dotsc + \\Phi(D_n) - \\Phi(D_{n-1})) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Bei der Teleskopsumme $\\sum \\Phi(D_i) - \\Phi(D_{i-1})$ kürzen sich alle Terme außer $\\Phi(D_n)$ und $\\Phi(D_0)$. Somit ergibt sich:\n",
    "\n",
    "__Korollar 4.4__\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\sum_{i=1}^n \\hat{c}_i &= \\sum_{i=1}^n c_i + \\Phi(D_n) - \\Phi(D_0) \\\\\n",
    "\\sum \\text{amortisierte Kosten} &= \\sum \\text{tatsächliche Kosten} + \\Phi(\\text{finale Datenstruktur}) - \\Phi(\\text{initiale Datenstruktur})\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "### Dynamische Arrays\n",
    "\n",
    "__*Beweis.*__ Bei dynamischen Arrays, deren Größe sich verdoppelt, wenn sie voll sind, lässt sich beispielsweise folgende Potenzialfunktion aufstellen:\n",
    "\n",
    "$$\n",
    "\\Phi(D_i) = 2n-m\n",
    "$$\n",
    "\n",
    "$n$ ist dabei die Anzahl der eigentlichen Elemente im dynamischen Array und $m$ ist die Anzahl der allozierten Speicherplätze. Direkt nach einer Verdopplungsoperation ist die Hälfte der Speicherplätze mit Elementen gefüllt, also $n = \\frac{m}{2}$. Damit ist \n",
    "\n",
    "$$\n",
    "\\Phi(D_i) = 2n-m = 2 \\cdot \\frac{m}{2} - m = 0\n",
    "$$\n",
    "\n",
    "$\\Phi(D_i) = 0$ bedeutet, dass die Datenstruktur weit entfernt von der nächsten tueren Operation ist. Kurz vor der Verdopplungsoperation beträgt $n = m$, also ist \n",
    "\n",
    "$$\n",
    "\\Phi(D_i) = 2n - m = 2m - m = m\n",
    "$$\n",
    "\n",
    "Nun kann sowohl für die billige, als auch für die teure Operation bewiesen werden, dass die amortisierten Kosten in beiden Fällen $\\mathcal{O}(1)$ betragen.\n",
    "\n",
    "##### Pushback Operation ohne Speicherallokation\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{c}_i &= c_i + \\Delta \\Phi(D_i) \\\\\n",
    " &= c_i + \\Phi(D_i) - \\Phi(D_{i-1}) \\\\\n",
    " &= 1 + 2(n+1) - m - (2n - m) \\\\\n",
    " &= 1 + 2 \\\\\n",
    " &= 3 \\\\\n",
    " &\\in \\mathcal{O}(1)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "##### Pushback Operation mit Speicherallokation\n",
    "\n",
    "In diesem Fall ist das momentane Array voll und es gilt $n = m$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{c}_i &= c_i + \\Delta \\Phi(D_i) \\\\\n",
    " &= c_i + \\Phi(D_i) - \\Phi(D_{i-1}) \\\\\n",
    " &= n + 1 + 2(n + 1) - 2m - (2n - m) \\\\\n",
    " &= n + 1 + 2 - m \\\\\n",
    " &= n + 1 + 2 - n \\\\\n",
    " &= 3 \\\\\n",
    " &\\in \\mathcal{O}(1)\n",
    "\\end{align*}\n",
    "$$\n",
    "<div style=\"text-align: right; font-size: 24px;\">&#9633;</div>\n",
    "\n",
    "### Binärzähler\n",
    "\n",
    "Beim Binärzahler könnte man zunächst intuitiv die Anzahl der hinterneinander folgenden Bits, die 1 sind, von hinten, als Potenzialfunktion nehmen. Demnach hätte 01001000 eine kleines Potenzial, ist also weit weg von teuren Operationen, 01111111 hätte demnach ein großes Potenzial, was auch zu stimmen scheint, da die nächste Operation zeitaufwendig sein wird. Betrachtet man aber beispielsweise 11111110, so wäre das Potenzial 0. Eine teure Operation ist also vermeindlich weit entfernt. Jedoch wird die übernächste Operation teuer. Die Anzahl der hinterneinander folgenden 1-Bits von hinten, scheint also keine passende Potenzialfuktion zu sein.\n",
    "\n",
    "Stattdessen ist die Gesamtzahl der 1-Bits der Binärzahl aussagekräftiger. Man spricht auch vom Hamming-Gewicht (hamming weight) der Binärzahl.\n",
    "\n",
    "$\\text{hamming_weight}(01001000) = 2$, $\\text{hamming_weight}(01111111) = 7$, $\\text{hamming_weight}(11111110) = 7$.\n",
    "\n",
    "__Definition 4.5__ Das Hamming-Gewicht einer Zeichenkette ist die Anzahl der vom Nullzeichen des verwendeten Alphabets verschiedenen Zeichen.\n",
    "\n",
    "Auch hier kann gezeigt werden, dass die amortisierten Kosten für eine Inkrementoperation $\\mathcal{O}(1)$ sind.\n",
    "\n",
    "__*Beweis.*__\n",
    "$$\n",
    "\\hat{c}_i = c_i + \\Delta \\Phi(D_i)\n",
    "$$\n",
    "\n",
    "Bei einem Inkrement einer Binärzahl werden alle aufeinanderfolgenden Bits, die 1 sind, zu 0 invertiert und das erste Bit von rechts, das 0 ist, wird zu 1 invertiert. Damit ergeben sich folgende Kosten $c$ für eine Binärzahl mit $t$ aufeinnanderfolgenden 1-Bits von hinten: $c = t + 1$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{c}_i &= t + 1 + \\Delta \\Phi(D_i) \\\\\n",
    " &= t + 1 + \\Phi(D_i) - \\Phi(D_{i-1}) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Das Potenzial $\\Phi(D_{i-1})$ vor der Inkrementoperation ist $\\text{hamming_weight}(b)$. Durch die Inkrementoperation werden $t$ aufeinanderfolgende 1-Bits zu 0, wodurch sich das Hamming-Gewicht um $t$ verkleinert. Das erste 0-Bit von hinten wird zu 1, dadurch vergrößert sich das Hamming-Gewicht um 1. Das Potenzial $\\Phi(D_i)$ nach der Inkrementoperation beträgt demnach $\\text{hamming_weight}(b) - t + 1$.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{c}_i &= t + 1 + \\Delta \\Phi(D_i) \\\\\n",
    " &= t + 1 + (\\text{hamming_weight}(b) - t + 1) - (\\text{hamming_weight}(b)) \\\\\n",
    " &= t + 1 - t + 1 \\\\\n",
    " &= 2 \\\\\n",
    " &\\in \\mathcal{O}(1)\n",
    "\\end{align*}\n",
    "$$\n",
    "<div style=\"text-align: right; font-size: 24px;\">&#9633;</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
