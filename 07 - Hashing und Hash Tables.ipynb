{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dictionary / Map\n",
    "\n",
    "Ein Dictionary, auch Map, genannt ist ein Abstrakter Datentyp, der in der Informatik sehr wichtig ist und sehr häufig zum Einsatz kommt. Er ist in allen gängingen Programmiersprachen implementiert.\n",
    "\n",
    "Ein Dictionary besteht aus Schlüssel-Wert-Paaren (key-value pairs). Dabei wird von einem Schlüssel auf einen Wert abgebildet. Es gibt drei wesentliche Operationen, nämlich __insert__, __get__ und __remove__.\n",
    "\n",
    "__insert(key, value)__:\n",
    "\n",
    "Die Insert-Operation fügt ein Paar aus einem Schlüssel und einem Wert in die Datenstruktur ein. Sowohl Schlüssel, als auch der Wert, auf den abgebildet werden soll, können von jedem erdenklichen Datentyp sein.\n",
    "\n",
    "__get(key)__:\n",
    "\n",
    "Diese Operation gibt den Wert, zu dem vom gesuchten Schlüssel abgebildet wird, zurück. Befindet sich kein Eintrag mit dem gesuchten Schlüssel im Dictionary, so wird __null__ zurückgegeben.\n",
    "\n",
    "__remove(key)__:\n",
    "\n",
    "Diese Operation entfernt einen Eintrag mit dem gegebenen Schlüssel aud dem Dictionary.\n",
    "\n",
    "Die genannten drei Operationen ließen sich mit ballancierten Bäumen, beispielsweise einem AVL-Baum, implementieren. Jedoch liegt die Laufzeit für diese Operationen bei einem balancierten Baum in $\\mathcal{O}(\\log n)$. Ziel in diesem Kapitel ist es, eine Datenstruktur zu implementieren, die dies in konstanter Zeit schafft.\n",
    "\n",
    "# Direct Access Table\n",
    "\n",
    "Bei diesem Implementierungsversuch weist man, wie bei einem Array, einen festen Bereich im Speicher der Datenstruktur zu. Nun kann man direkt über den Index auf jeden Slot zugreifen. Sind die Schlüssel nicht-negative Integers, so kann man festlegen, dass der Schlüssel immer genau dem Index des Slots entspricht.\n",
    "\n",
    "Dies wirft zwei Probleme auf. Zum einen möchte man eine Datenstruktur haben, bei welchem die Schlüssel von einem beliebigen Datentyp sind (Es wurde als Bedingung angenommen, dass es sich um nicht-negative Integers handelt). Zum anderen beträgt der Speicheraufwand $\\mathcal{O}(\\left| U \\right|)$. $U$ ist dabei das Schlüsseluniversum. Dies wäre absolut unpraktikabel.\n",
    "\n",
    "__Definition 7.1__\n",
    "Das Schlüsseluniversum $U$ ist die Menge aller möglichen Schlüssel.\n",
    "\n",
    "__Definition 7.2__\n",
    "Die Schlüsselmenge $K$ ist die Menge aller Schlüssel, die sich derzeitig in einem Dictionary befinden.\n",
    "\n",
    "__Satz 7.3__\n",
    "$K \\subset U$\n",
    "\n",
    "<img src=\"http://faculty.ycp.edu/~dbabcock/PastCourses/cs360/lectures/images/lecture11/directaddress.png\" width=\"400\">\n",
    "\n",
    "Die Kardinalität $\\left| K \\right|$ der Schlüsselmenge $K$ wird im folgenden $n$ genannt. Sie entspricht der Anzahl der Elemente, die sich momentan in der Datenstruktur befinden.\n",
    "\n",
    "# Hash Table\n",
    "\n",
    "Eine Hash Table bzw. Hash Map ist eine Implementation des ADT Dictionary. Dabei wird auch per direkten Slotzugriff, wie bei der Direct Access Table, vorgegangen. Jedoch gibt es eine feste Anzahl $m$ an Slots, wobei gilt $m \\ll \\left| U \\right|$. Nun wird eine Hashfunktion $h: U \\to \\{0, 1, \\dotsc, m-1\\}$ benötigt, die vom Schlüsseluniversum auf einen der Slots $\\{0, 1, \\dotsc, m-1\\}$ abbildet. Eine einfach solche Funktion wäre $h: k \\mapsto k \\bmod m$.\n",
    "\n",
    "Somit wurde der Speicheraufwand deutlich reduziert.\n",
    "\n",
    "Um das Problem, dass es sich bei den Schlüsseln um etwas anderes als nicht-negative Integers, z.B. Strings, handeln kann, zu lösen, wird eine sogenannte pre-hash Funktion benötigt. Dies ist eine Funktion, die vom Schlüsseluniversum auf eine nicht-negative ganze Zahl abbildet. Theoretisch betrachtet ist dies immer möglich, da alles, was in einem Computer dargstellt wird, diskret und endlich ist. Schließlich könnte man die Bits, durch welche das entsprechende Datum dargstellt wird, als nicht-negativen Integer auffassen und dies als den pre-hash-Wert nehmen. Dies würde jedoch mitunter zu sehr großen Zahlen führen, weshalb man in der Praxis meist bessere pre-hash-Funktionen nimmt. Hat man beispielsweise einen String mit Zeichen zwischen a-z, so könnte man den String als Zahl auffassen, die ensprechend Basis 26 hat.\n",
    "\n",
    "__Beispiel__:\n",
    "\n",
    "$h('adf') = 0 \\cdot 26^2 + 3 \\cdot 26 + 5 \\cdot 1 = 83$\n",
    "\n",
    "Nun kann man mit dem geprehashten Wert, der ein nicht-negativer Integer ist, so umgehen, als wäre dieser der eigentliche Schlüssel. \n",
    "\n",
    "In der Programmierpsrache Java beispielsweise findet dieses Pre-Hashing durch die hashCode()-Methode, die jede Klasse implementiert, statt.\n",
    "\n",
    "## Kollisionen\n",
    "\n",
    "Durch die Tatsache, dass $m < \\left| U \\right|$ gilt, ensteht ein neues Problem, welches behandelt werden muss, nämlich Kollisionen.\n",
    "\n",
    "__Definition 7.4__\n",
    "Eine Kollision unter der Hashfunktion $h$ tritt auf, wenn für $k_i, k_j \\in K$ mit $i \\neq j$ gilt, dass $h(k_i) = h(k_j)$.\n",
    "\n",
    "<img src=\"http://www.cs.fsu.edu/~burmeste/slideshow/images_content/figure12_2.gif\" width=\"450\">\n",
    "\n",
    "Eine  Kollision tritt also auf, wenn zwei oder mehrere unterschiedliche Schlüssel den gleichen Hash-Wert haben. Dies hat zur Folge, dass sie sich den gleichen Slot in der Hash Map teilen müssten. Um dieses Problem zu behandeln gibt es mehrere Verfahren. Im Folgenden werden Hashing with Chaining und Open Addressing vorgestellt.\n",
    "\n",
    "## Hashing with Chaining\n",
    "\n",
    "Bei __Hashing with Chaining__ wird in einem Slot der Hash Table anstatt einem Wert eine Linked List von Schlüssel-Wert-Paaren gespeichert. Kommt es beim Einfügen zu einer Kollision, so fügt man das Schlüssel-Wert-Paar ans Ende dieser List ein. Möchte man nach eine Schlüssel suchen, so muss man die Liste an dem entsprechenden Slot iterieren. \n",
    "\n",
    "<img src=\"http://www.cs.fsu.edu/~burmeste/slideshow/images_content/figure12_3.gif\" width=\"450\">\n",
    "\n",
    "Handelt es sich um eine sehr schlechte Hashfunktion, bei der es viele Kollisionen gibt, so kann es passieren, dass (fast) alle Schlüssel den gleichen Hash-Wert haben und somit eine Linked List mit der Länge $\\mathcal{O}(n)$ bilden. $n$ ist dabei die Anzahl der Elemente in der Datenstruktur, $n = \\left| K \\right|$. Die worst-case Komplexität liegt somit für alle Operationen in $\\mathcal{O}(n)$. Für gute Klassen von Hashfunktionen tritt dieser worst-case jedoch mit einer sehr geringen Wahrscheinlichkeit ein. Man kann $\\mathcal{O}(\\log n)$ im worst-case erreichen, indem man statt Linked Lists ballancierte Bäume verwendet.\n",
    "\n",
    "## Simple Uniform Hashing\n",
    "\n",
    "Man spricht von Simple Uniform Hashing, wenn die Hashfunktion $h$ die Schlüsselmenge $K$ uniform zufällig auf die Werte $\\{0, 1, \\dotsc, m-1\\}$ verteilt. Uniform zufällig bedeutet, dass jeder Hash-Wert gleich wahrscheinlich auftreten kann, so als ob man den Hash-Wert durch zufälliges Werfen bestimmt. Die Annahme, dass die Verteilung der Hash-Werte uniform ist, tritt in der Praxis nicht ein, jedoch hilft diese Annahme um zu verstehen, warum Operationen in einer Hash Map eine erwartete Laufzeit von $\\mathcal{O}(1)$ haben.\n",
    "\n",
    "__Beweis.__\n",
    "Der Erwartungswert für die Anzahl der Elemente in einem Slot unter der Annahme von Uniform Hashing ist $n \\cdot \\frac{1}{m} = \\frac{n}{m}$. Nehmen wir an, dass $n \\in \\mathcal{O}(m)$, also die Anzahl der Elemente $n$ maximal ein konstantes Vielfaches von der Anzahl der Slots $m$ ist, so befinden sich vorraussichtlich $\\leqslant \\frac{c \\cdot m}{m} = c$ Elemente in einer Liste. Da $c$ eine Konstante ist, befinden sich lediglich $\\mathcal{O}(1)$ Elemente in einer Liste.\n",
    "<div style=\"text-align: right; font-size: 24px;\">&#9633;</div>\n",
    "\n",
    "\n",
    "## Table Doubling\n",
    "\n",
    "Das Problem ist, dass $n$ kein fester Wert und somit unbekannt ist, schließlich können ständig Werte in das Dictionary eingefügt und entfernt werden. Ist $n$ nämlich viel größer als $m$, so sind die Listen, durch die iteriert werden muss, sehr lang und somit wäre die Datenstruktur ineffizient. Wie kann man also sicherstellen, dass $n \\in \\mathcal{O}(m)$ immer gilt? Hierfür wird eine Technik angewandt, die bereits von dynamischen Arrays bekannt ist, nämlich das Verdoppeln der Größe, sobald die Anzahl der Elemente zu groß wird. Man spricht hier von Table Doubling.\n",
    "\n",
    "Sobald $n > m$ ist, wird Table Doubling durchgeführt. Dabei wird die Anzahl der Slots $m$ verdoppelt. Die Anzahl der Slots nach Table Doubling nennen wir $m'=2m$. Um die Elemente nun auf $m'$ Slots zu verteilen, ist eine neue Hashfunktion nötig. Handelt es sich beispielsweise um die sehr einfache Hashfunktion $h: x \\mapsto x \\bmod m$, so wird sie entsprechend zu $h': x \\mapsto x \\bmod m'$ abgeändert. Die bereits eingefügten Elemente werden nun entsprechend der neuen Hashfunktion $h'$ neu eingefügt, man spricht hier von Rehashing. Die Kosten für die ganze Table Doubling Operation betragen $\\mathcal{O}(n)$. Man kann aber zeigen, dass die Kosten amortisiert weiterhin bloß $\\mathcal{O}(1)$ betragen. Der Beweis entspricht genau dem von einem dynamischen Array.\n",
    "\n",
    "Durch Table Doubling ist sichergestellt, dass $n \\in \\mathcal{O}(m)$ immer gilt und somit die erwartete Laufzeit mit Uniform Hashing $\\mathcal{O}(1)$ beträgt.\n",
    "\n",
    "## Open Addressing\n",
    "\n",
    "Open Addressing ist eine andere Variante um eine Hash Map zu implementieren. Dabei gibt es keine Verkettung, sondern es wird immer maximal ein Element in einem Slot gespeichert. Somit muss $m \\geqslant n$ gelten. \n",
    "\n",
    "__Insert__\n",
    "\n",
    "Möchte man ein Element einfügen, das einen Hash-Wert hat, welcher einem Slot entspricht, der schon belegt ist, so berechnet man einen neuen Hash und fügt das Element an dieser Stelle ein, falls dieser Slot frei ist. Die Hashfunktion bei Open Addressing ist also eine spezielle Hashfunktion, die nicht nur den Schlüssel als Paramter nimmt, sondern auch die Zahl der Versuches, um den es sich handelt. Die Hashfunktion $h$ ist also von der Form \n",
    "\n",
    "$$\n",
    "h: U \\times \\{0, 1, \\dotsc, m-1\\} \\to \\{0, 1, \\dotsc, m-1\\}\n",
    "$$.\n",
    "\n",
    "Eine entscheidende Anforderung an solch eine Hashfunktion ist, dass der Vektor \n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}h(k, 0) & h(k, 1) & \\cdots & h(k, m-1) \\end{pmatrix}\n",
    "$$ \n",
    "\n",
    "eine Permutation des Vektors \n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}0 & 1 & \\cdots & m-1 \\end{pmatrix}\n",
    "$$ \n",
    "\n",
    "ist.\n",
    "\n",
    "Dies bedeutet, dass man nach $m$ Versuchen jeden der $m$ Slots genau einmal \"durchprobiert\" hat. Unter der Bedingung $n \\geqslant m$, findet man demnach in jedem Fall einen freien Slot.\n",
    "\n",
    "__Search__\n",
    "\n",
    "Um einen Schlüssel zu suchen, wendet man die Hashfunktion $h$ ebenfalls mit entsprechendem Versuchszähler an. Man beginnt mit der Versuchszahl 0. Hat man Glück und findet den Schlüssel an dem entsprechenden Slot, so kann man an aufhören und hat das Element gefunden. Handelt es sich um einen __null__ Wert, so kann man auch aufhören, mit der Erkenntnis, dass sich der gesucht Schlüssel nicht in der Hash Map befindet. Findet man an dem entsrechenden Slot, einen anderen Schlüssel, so muss man einen neuen Hash-Wert mit inkrementierten Versuchszähler berechnen. \n",
    "\n",
    "Dass man bei einem __null__ Wert aufhören kann, liegt daran, dass wenn der zu suchende Schlüssel sich in der Datenstruktur befände, man ihn genau an dieser Stelle eingefügt hätte. Da er sich aber nicht dort befindet, befindet er sich auch nirgendswo anders in der Hash Map.\n",
    "\n",
    "__Remove__\n",
    "\n",
    "Das Entfernen von Schlüsseln aus einer Hash Table mit Open Addressing stellt sich etwas problematisch dar. Entfernt man nämlich ein Element, so funktioniert die Scuhe nicht mehr, da die Probiersequenz, die zum eigentlichen Schlüssel führen soll nun durch ein gelöschtes Element unterbrochen wurde und der Suchalgorithmus denken würde, der Schlüssel befindet sich nicht in der Hash Table. Aus diesem Grund darf man das Element nicht einfach entfernen, sondern man muss einen __deleted__-Marker einführen, der signalisiert, dass man weitersuchen muss, da sich hier mal ein Schlüssel befand. Der Suchalgorithmus bleibt prinzipiell der gleiche. Trifft man auf __null__-Wert, so kann man aufhören. Hat man den gesuchten Schlüssel gefunden, so kann man ebenfalls aufhören. Bei jedem anderen Wert - __deleted__-Marker eingeschlossen - muss man mit inkrementierten Versuchszähler weiterprobieren.\n",
    "\n",
    "Nun stellt sich die Frage, wie man eine Hashfunktion entwickelt, die den Anforderungen von Open Addressing entspricht. Sie muss zusätzlich eine versuchszahl als Parameter nehmen und alle $m$ Slots genau einmal zurückgeben.\n",
    "\n",
    "### Linear Probing\n",
    "\n",
    "Die naheliegenste Variante ist es, einfach beim nächsten Versuch um einen Slot weiterzugehen. Also entwirft man einfach folgende Hashfunktion, wobei $h'$ eine gewöhnliche Hashfunktion vom Type $U \\to \\{0, 1, \\dotsc, m-1\\}$ ist.\n",
    "\n",
    "$$\n",
    "h(k, i) = h'(k) + i \\bmod m\n",
    "$$\n",
    "\n",
    "Diese Hashfunktion ist einfach, aber leider schlecht. Hat sich etwa ein Cluster in der Hash Map gebildet (ein Zustand bei der viele Slots unmittelbar hintereinander belegt sind), so muss man defintiv das komplette Cluster durchiterieren, bis man einen freien Platz findet. Zudem hat man jetzt dieses Cluster auch noch um 1 vergrößert. Je größer ein Cluster ist, desto größer ist such die Wahrscheinlichkeit es beim ersten Versuch zu treffen. Genau genommen $\\frac{k}{m}$, wenn $k$ die Größe des Clusters ist und $m$ die Anzahl der Slots in der Hash Map.\n",
    "\n",
    "### Double Hashing\n",
    "\n",
    "Double Hashing verwendet, wie der Name bereits impliziert, zwei zufällig ausgewählte Hashfunktionen $h_1$ und $h_2$. Die Hashfunkction $h$ wird folgendermaßen derfiniert:\n",
    "\n",
    "$$\n",
    "h(k, i) = \\left( h_1(k) + i h_2(k) \\right) \\bmod m\n",
    "$$\n",
    "\n",
    "Damit sichergestellt ist, dass die Hashfunktion die erforderte Permutation erzeugt, müssen alle Werte con $h_2(k)$ und $m$ relativ prim, also teilerfremd, sein.\n",
    "\n",
    "Diese Hashfunktion erzeugt eine wesentlich druchmischtere Verteilung der Hash-Werte, wodurch sich (wahrscheinlich) keine Cluster bilden und somit besser geeignet ist."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
